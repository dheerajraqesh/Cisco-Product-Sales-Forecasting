{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II49_-JNx5iQ",
        "outputId": "9e806cb7-e316-4e24-c8d6-4ae002eae86f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Random Forest\n",
            "  Avg Bias: 0.0142\n",
            "  Avg Accuracy: 0.8259\n",
            "\n",
            "Model: Linear Regression\n",
            "  Avg Bias: 0.0113\n",
            "  Avg Accuracy: 0.8430\n",
            "\n",
            "Model: Gradient Boosting\n",
            "  Avg Bias: 0.0114\n",
            "  Avg Accuracy: 0.8430\n",
            "\n",
            "Model: Decision Tree\n",
            "  Avg Bias: 0.0113\n",
            "  Avg Accuracy: 0.8430\n",
            "\n",
            "‚úÖ Best model selected: Linear Regression\n",
            "üìÅ Final forecast with real-world randomness saved as 'CFL_DS2_FY25Q2_Forecasted_Simulated.xlsx'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Load and clean data\n",
        "df = pd.read_excel(\"CFL_DS2.xlsx\")\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Define available quarters\n",
        "quarter_targets = [q for q in [\"FY24 Q3\", \"FY24 Q4\", \"FY25 Q1\", \"FY25 Q2\"] if q in df.columns]\n",
        "\n",
        "# Feature columns (exclude all targets and Product Name)\n",
        "feature_cols = [col for col in df.columns if col not in [\"Product Name\"] + quarter_targets]\n",
        "\n",
        "# Identify column types\n",
        "numeric_cols = df[feature_cols].select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "categorical_cols = df[feature_cols].select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "# Preprocessing\n",
        "numeric_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", numeric_transformer, numeric_cols),\n",
        "    (\"cat\", categorical_transformer, categorical_cols)\n",
        "])\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "def evaluate_model(model, X_eval, y_eval):\n",
        "    preds = model.predict(X_eval)\n",
        "    bias = (preds - y_eval) / y_eval\n",
        "    accuracy = np.maximum(0, 1 - np.abs(bias))\n",
        "    return np.mean(bias), np.mean(accuracy)\n",
        "\n",
        "# Model scoring\n",
        "model_scores = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    all_bias = []\n",
        "    all_accuracy = []\n",
        "\n",
        "    for i in range(len(quarter_targets) - 1):\n",
        "        current_q = quarter_targets[i]\n",
        "        next_q = quarter_targets[i + 1]\n",
        "\n",
        "        train_mask = df[current_q].notna()\n",
        "        X_train = df.loc[train_mask, feature_cols]\n",
        "        y_train = df.loc[train_mask, current_q]\n",
        "\n",
        "        eval_mask = df[next_q].notna()\n",
        "        X_eval = df.loc[eval_mask, feature_cols]\n",
        "        y_eval = df.loc[eval_mask, next_q]\n",
        "\n",
        "        if len(X_train) == 0 or len(X_eval) == 0:\n",
        "            continue\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            (\"preprocessor\", preprocessor),\n",
        "            (\"regressor\", model)\n",
        "        ])\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        bias, accuracy = evaluate_model(pipeline, X_eval, y_eval)\n",
        "        all_bias.append(bias)\n",
        "        all_accuracy.append(accuracy)\n",
        "\n",
        "    avg_bias = np.mean(all_bias)\n",
        "    avg_accuracy = np.mean(all_accuracy)\n",
        "\n",
        "    model_scores.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Avg Bias\": avg_bias,\n",
        "        \"Avg Accuracy\": avg_accuracy\n",
        "    })\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"  Avg Bias: {avg_bias:.4f}\")\n",
        "    print(f\"  Avg Accuracy: {avg_accuracy:.4f}\\n\")\n",
        "\n",
        "# Select best model\n",
        "best_model_info = max(model_scores, key=lambda x: x[\"Avg Accuracy\"])\n",
        "best_model_name = best_model_info[\"Model\"]\n",
        "best_model_obj = models[best_model_name]\n",
        "\n",
        "print(f\"Best model selected: {best_model_name}\")\n",
        "\n",
        "# Final training on FY25 Q1 ‚Üí Predict FY25 Q2\n",
        "train_mask = df[\"FY25 Q1\"].notna()\n",
        "X_train_final = df.loc[train_mask, feature_cols]\n",
        "y_train_final = df.loc[train_mask, \"FY25 Q1\"]\n",
        "X_forecast = df[feature_cols]\n",
        "\n",
        "final_pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", best_model_obj)\n",
        "])\n",
        "final_pipeline.fit(X_train_final, y_train_final)\n",
        "\n",
        "# Predict\n",
        "y_pred_point = final_pipeline.predict(X_forecast)\n",
        "\n",
        "# Add realistic randomness using bootstrapped residuals + stochastic drift ---\n",
        "y_train_pred = final_pipeline.predict(X_train_final)\n",
        "residuals = y_train_final - y_train_pred\n",
        "\n",
        "# Bootstrapping from residuals (real-world-like noise)\n",
        "n_simulations = 1000\n",
        "simulated_forecasts = []\n",
        "\n",
        "for _ in range(n_simulations):\n",
        "    # 1. Bootstrapped residuals\n",
        "    bootstrapped_residuals = np.random.choice(residuals, size=len(X_forecast), replace=True)\n",
        "\n",
        "    # 2. Add mild stochastic drift (simulating market conditions)\n",
        "    drift_factor = np.random.normal(loc=1.0, scale=0.02, size=len(X_forecast))  # small random upward/downward movement\n",
        "\n",
        "    # 3. Combine base forecast + bootstrapped error + drift\n",
        "    simulated = (y_pred_point + bootstrapped_residuals) * drift_factor\n",
        "    simulated_forecasts.append(simulated)\n",
        "\n",
        "simulated_forecasts = np.array(simulated_forecasts)\n",
        "mean_forecast = simulated_forecasts.mean(axis=0)\n",
        "lower_bound = np.percentile(simulated_forecasts, 5, axis=0)\n",
        "upper_bound = np.percentile(simulated_forecasts, 95, axis=0)\n",
        "\n",
        "# Save results\n",
        "df[\"FY25 Q2 (Forecasted Mean)\"] = mean_forecast\n",
        "df[\"FY25 Q2 (Lower Bound 5%)\"] = lower_bound\n",
        "df[\"FY25 Q2 (Upper Bound 95%)\"] = upper_bound\n",
        "\n",
        "# Export output\n",
        "df.to_excel(\"CFL_DS2_FY25Q2_Forecasted_Simulated.xlsx\", index=False)\n",
        "print(\"Final forecast with real-world randomness saved as 'CFL_DS2_FY25Q2_Forecasted_Simulated.xlsx'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Load data\n",
        "df = pd.read_excel(\"CFL_DS2_FY25Q2_Forecasted_Simulated.xlsx\")\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Forecast sources to blend\n",
        "forecast_columns_q2 = [\n",
        "    \"Demand Planners Forecast\",\n",
        "    \"Marketing Teams Forecast\",\n",
        "    \"Statistical and ML Forecast\",\n",
        "    \"FY25 Q2 (Forecasted Mean)\"\n",
        "]\n",
        "\n",
        "# Check if similar forecasts exist for Q1 (for training)\n",
        "forecast_columns_q1 = [col.replace(\"Q2\", \"Q1\") for col in forecast_columns_q2]\n",
        "if all(col in df.columns for col in forecast_columns_q1) and \"FY25 Q1\" in df.columns:\n",
        "    print(\"Using FY25 Q1 forecast sources to train blending model.\")\n",
        "\n",
        "    X_train = df[forecast_columns_q1]\n",
        "    y_train = df[\"FY25 Q1\"]\n",
        "\n",
        "    # Drop rows where any forecast or target is missing\n",
        "    valid_rows = X_train.notna().all(axis=1) & y_train.notna()\n",
        "    X_train = X_train[valid_rows]\n",
        "    y_train = y_train[valid_rows]\n",
        "\n",
        "    # Train meta-model (Linear or Gradient Boosting)\n",
        "    meta_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "    meta_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict for FY25 Q2 by blending its forecast sources\n",
        "    X_q2_blend = df[forecast_columns_q2].fillna(0)  # or choose a better imputation\n",
        "    df[\"FY25 Q2 (Model-Based Combined Forecast)\"] = meta_model.predict(X_q2_blend)\n",
        "\n",
        "else:\n",
        "    print(\"FY25 Q1 forecast source columns not found. Falling back to equal average blending.\")\n",
        "    df[\"FY25 Q2 (Model-Based Combined Forecast)\"] = df[forecast_columns_q2].mean(axis=1)\n",
        "\n",
        "# Save final forecast\n",
        "df.to_excel(\"CFL_DS_FY25Q2_CombinedForecast.xlsx\", index=False)\n",
        "print(\"üìÅ Final combined forecast saved as 'CFL_DS_FY25Q2_CombinedForecast.xlsx'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI8xw2zKzs3y",
        "outputId": "be0a40df-e038-4a81-debd-f08cc8e061e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è FY25 Q1 forecast source columns not found. Falling back to equal average blending.\n",
            "üìÅ Final combined forecast saved as 'CFL_DS_FY25Q2_CombinedForecast.xlsx'\n"
          ]
        }
      ]
    }
  ]
}